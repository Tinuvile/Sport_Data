#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼“å­˜ç®¡ç†å·¥å…·
ç®¡ç† FunASR æ¨¡å‹ç¼“å­˜ï¼ŒåŒ…æ‹¬æ¸…ç†ã€è¿ç§»ç­‰åŠŸèƒ½
"""

import os
import shutil
import argparse
import logging
from pathlib import Path
from typing import Dict, List
import config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# é»˜è®¤çš„æ—§ç¼“å­˜ä½ç½®
OLD_CACHE_LOCATIONS = [
    Path.home() / ".cache",
    Path("C:/Users/ASUS/.cache") if os.name == 'nt' else Path.home() / ".cache",
    Path.home() / ".modelscope",
    Path.home() / ".huggingface",
]


def get_directory_size(path: Path) -> int:
    """è·å–ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
    total_size = 0
    try:
        for dirpath, dirnames, filenames in os.walk(path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                if os.path.exists(fp):
                    total_size += os.path.getsize(fp)
    except Exception as e:
        logger.warning(f"è®¡ç®—ç›®å½•å¤§å°å¤±è´¥ {path}: {e}")
    return total_size


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0 B"
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.1f} {size_names[i]}"


def scan_cache_directories() -> Dict[str, Dict]:
    """æ‰«ææ‰€æœ‰ç¼“å­˜ç›®å½•"""
    logger.info("æ‰«æç¼“å­˜ç›®å½•...")
    
    cache_info = {}
    
    # å½“å‰é…ç½®çš„ç¼“å­˜ç›®å½•
    current_cache = Path(config.CUSTOM_CACHE_ROOT)
    if current_cache.exists():
        size = get_directory_size(current_cache)
        cache_info["current"] = {
            "path": str(current_cache),
            "exists": True,
            "size": size,
            "formatted_size": format_size(size),
            "description": "å½“å‰é…ç½®çš„ç¼“å­˜ç›®å½• (Gç›˜)"
        }
    else:
        cache_info["current"] = {
            "path": str(current_cache),
            "exists": False,
            "size": 0,
            "formatted_size": "0 B",
            "description": "å½“å‰é…ç½®çš„ç¼“å­˜ç›®å½• (Gç›˜) - ä¸å­˜åœ¨"
        }
    
    # æ‰«æå¯èƒ½çš„æ—§ç¼“å­˜ä½ç½®
    old_caches = {}
    for old_location in OLD_CACHE_LOCATIONS:
        for cache_type in ["modelscope", "huggingface", "torch"]:
            old_cache_path = old_location / cache_type
            if old_cache_path.exists():
                size = get_directory_size(old_cache_path)
                old_caches[f"{old_location.name}_{cache_type}"] = {
                    "path": str(old_cache_path),
                    "exists": True,
                    "size": size,
                    "formatted_size": format_size(size),
                    "description": f"æ—§ç¼“å­˜: {cache_type} åœ¨ {old_location}"
                }
    
    cache_info["old"] = old_caches
    
    return cache_info


def show_cache_status():
    """æ˜¾ç¤ºç¼“å­˜çŠ¶æ€"""
    logger.info("=" * 60)
    logger.info("FunASR ç¼“å­˜çŠ¶æ€æŠ¥å‘Š")
    logger.info("=" * 60)
    
    cache_info = scan_cache_directories()
    
    # æ˜¾ç¤ºå½“å‰ç¼“å­˜
    current = cache_info["current"]
    logger.info(f"\nğŸ“ {current['description']}")
    logger.info(f"   è·¯å¾„: {current['path']}")
    logger.info(f"   å¤§å°: {current['formatted_size']}")
    logger.info(f"   çŠ¶æ€: {'âœ“ å­˜åœ¨' if current['exists'] else 'âœ— ä¸å­˜åœ¨'}")
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    logger.info(f"\nâš™ï¸  ç¯å¢ƒå˜é‡é…ç½®:")
    logger.info(f"   MODELSCOPE_CACHE: {os.environ.get('MODELSCOPE_CACHE', 'æœªè®¾ç½®')}")
    logger.info(f"   HF_HOME: {os.environ.get('HF_HOME', 'æœªè®¾ç½®')}")
    logger.info(f"   TORCH_HOME: {os.environ.get('TORCH_HOME', 'æœªè®¾ç½®')}")
    
    # æ˜¾ç¤ºæ—§ç¼“å­˜
    old_caches = cache_info["old"]
    if old_caches:
        logger.info(f"\nâš ï¸  å‘ç°æ—§ç¼“å­˜ç›®å½•:")
        total_old_size = 0
        for name, info in old_caches.items():
            logger.info(f"   {info['description']}")
            logger.info(f"     è·¯å¾„: {info['path']}")
            logger.info(f"     å¤§å°: {info['formatted_size']}")
            total_old_size += info['size']
        
        logger.info(f"\nğŸ“Š æ—§ç¼“å­˜æ€»å¤§å°: {format_size(total_old_size)}")
        logger.info(f"ğŸ’¡ å»ºè®®: è¿è¡Œ 'python cache_manager.py --migrate' è¿ç§»æ—§ç¼“å­˜")
    else:
        logger.info(f"\nâœ“ æœªå‘ç°æ—§ç¼“å­˜ç›®å½•")
    
    # æ˜¾ç¤ºç£ç›˜ç©ºé—´
    space_info = config.check_cache_space()
    if space_info and "error" not in space_info:
        logger.info(f"\nğŸ’¾ Gç›˜ç©ºé—´çŠ¶æ€:")
        logger.info(f"   æ€»å®¹é‡: {space_info['total_gb']} GB")
        logger.info(f"   å·²ä½¿ç”¨: {space_info['used_gb']} GB")
        logger.info(f"   å‰©ä½™ç©ºé—´: {space_info['free_gb']} GB")
        logger.info(f"   ä½¿ç”¨ç‡: {space_info['usage_percent']:.1f}%")


def migrate_cache():
    """è¿ç§»æ—§ç¼“å­˜åˆ°æ–°ä½ç½®"""
    logger.info("å¼€å§‹è¿ç§»ç¼“å­˜åˆ° Gç›˜...")
    
    cache_info = scan_cache_directories()
    old_caches = cache_info["old"]
    
    if not old_caches:
        logger.info("âœ“ æœªå‘ç°éœ€è¦è¿ç§»çš„æ—§ç¼“å­˜")
        return
    
    # ç¡®ä¿æ–°ç¼“å­˜ç›®å½•å­˜åœ¨
    config.setup_cache_directories()
    
    migrated_count = 0
    total_migrated_size = 0
    
    for name, info in old_caches.items():
        if not info['exists']:
            continue
            
        old_path = Path(info['path'])
        
        # ç¡®å®šæ–°è·¯å¾„
        if "modelscope" in name:
            new_path = Path(config.CUSTOM_CACHE_ROOT) / "modelscope"
        elif "huggingface" in name:
            new_path = Path(config.CUSTOM_CACHE_ROOT) / "huggingface"
        elif "torch" in name:
            new_path = Path(config.CUSTOM_CACHE_ROOT) / "torch"
        else:
            continue
        
        try:
            logger.info(f"è¿ç§» {old_path} -> {new_path}")
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            new_path.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ–‡ä»¶
            for item in old_path.iterdir():
                if item.is_file():
                    shutil.copy2(item, new_path / item.name)
                elif item.is_dir():
                    shutil.copytree(item, new_path / item.name, dirs_exist_ok=True)
            
            migrated_count += 1
            total_migrated_size += info['size']
            
            logger.info(f"âœ“ è¿ç§»å®Œæˆ: {format_size(info['size'])}")
            
        except Exception as e:
            logger.error(f"âœ— è¿ç§»å¤±è´¥ {old_path}: {e}")
    
    if migrated_count > 0:
        logger.info(f"\nğŸ‰ è¿ç§»å®Œæˆ!")
        logger.info(f"   è¿ç§»ç›®å½•æ•°: {migrated_count}")
        logger.info(f"   è¿ç§»æ•°æ®é‡: {format_size(total_migrated_size)}")
        logger.info(f"   æ–°ç¼“å­˜ä½ç½®: {config.CUSTOM_CACHE_ROOT}")
        
        # è¯¢é—®æ˜¯å¦åˆ é™¤æ—§ç¼“å­˜
        response = input("\næ˜¯å¦åˆ é™¤æ—§ç¼“å­˜ç›®å½•? (y/N): ").strip().lower()
        if response == 'y':
            clean_old_cache()
    else:
        logger.info("æ²¡æœ‰æˆåŠŸè¿ç§»ä»»ä½•ç›®å½•")


def clean_old_cache():
    """æ¸…ç†æ—§ç¼“å­˜ç›®å½•"""
    logger.info("æ¸…ç†æ—§ç¼“å­˜ç›®å½•...")
    
    cache_info = scan_cache_directories()
    old_caches = cache_info["old"]
    
    if not old_caches:
        logger.info("âœ“ æ²¡æœ‰æ—§ç¼“å­˜éœ€è¦æ¸…ç†")
        return
    
    cleaned_count = 0
    total_cleaned_size = 0
    
    for name, info in old_caches.items():
        if not info['exists']:
            continue
            
        old_path = Path(info['path'])
        
        try:
            logger.info(f"åˆ é™¤ {old_path}")
            shutil.rmtree(old_path)
            
            cleaned_count += 1
            total_cleaned_size += info['size']
            
            logger.info(f"âœ“ åˆ é™¤å®Œæˆ: {format_size(info['size'])}")
            
        except Exception as e:
            logger.error(f"âœ— åˆ é™¤å¤±è´¥ {old_path}: {e}")
    
    if cleaned_count > 0:
        logger.info(f"\nğŸ§¹ æ¸…ç†å®Œæˆ!")
        logger.info(f"   åˆ é™¤ç›®å½•æ•°: {cleaned_count}")
        logger.info(f"   é‡Šæ”¾ç©ºé—´: {format_size(total_cleaned_size)}")


def clean_current_cache():
    """æ¸…ç†å½“å‰ç¼“å­˜ç›®å½•"""
    logger.info("æ¸…ç†å½“å‰ç¼“å­˜ç›®å½•...")
    
    cache_path = Path(config.CUSTOM_CACHE_ROOT)
    
    if not cache_path.exists():
        logger.info("âœ“ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
        return
    
    # ç¡®è®¤æ¸…ç†
    size = get_directory_size(cache_path)
    logger.warning(f"å°†åˆ é™¤ {cache_path} ({format_size(size)})")
    response = input("ç¡®è®¤æ¸…ç†? (y/N): ").strip().lower()
    
    if response != 'y':
        logger.info("å–æ¶ˆæ¸…ç†")
        return
    
    try:
        shutil.rmtree(cache_path)
        logger.info(f"âœ“ æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾ç©ºé—´: {format_size(size)}")
        
        # é‡æ–°åˆ›å»ºç›®å½•ç»“æ„
        config.setup_cache_directories()
        logger.info("âœ“ é‡æ–°åˆ›å»ºç¼“å­˜ç›®å½•ç»“æ„")
        
    except Exception as e:
        logger.error(f"âœ— æ¸…ç†å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="FunASR ç¼“å­˜ç®¡ç†å·¥å…·")
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºç¼“å­˜çŠ¶æ€')
    parser.add_argument('--migrate', action='store_true', help='è¿ç§»æ—§ç¼“å­˜åˆ°æ–°ä½ç½®')
    parser.add_argument('--clean-old', action='store_true', help='æ¸…ç†æ—§ç¼“å­˜ç›®å½•')
    parser.add_argument('--clean-current', action='store_true', help='æ¸…ç†å½“å‰ç¼“å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    if args.status:
        show_cache_status()
    elif args.migrate:
        migrate_cache()
    elif args.clean_old:
        clean_old_cache()
    elif args.clean_current:
        clean_current_cache()
    else:
        # é»˜è®¤æ˜¾ç¤ºçŠ¶æ€
        show_cache_status()
        print("\nå¯ç”¨å‘½ä»¤:")
        print("  python cache_manager.py --status       - æ˜¾ç¤ºç¼“å­˜çŠ¶æ€")
        print("  python cache_manager.py --migrate      - è¿ç§»æ—§ç¼“å­˜")
        print("  python cache_manager.py --clean-old    - æ¸…ç†æ—§ç¼“å­˜")
        print("  python cache_manager.py --clean-current - æ¸…ç†å½“å‰ç¼“å­˜")


if __name__ == "__main__":
    main() 